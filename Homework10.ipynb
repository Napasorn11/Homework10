{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1 style = \"text-align: center\">\n",
    "    <a href = \"https://docs.opencv.org/4.5.3/d8/dfe/classcv_1_1VideoCapture.html\">VideoCapture</a>\n",
    "</h1>\n",
    "<h2 style = \"text-align: center\">\n",
    "is class for video capturing from video files, image sequences or cameras.\n",
    "</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "cap = cv2.VideoCapture(0) # 0 is a id-number of video devices\r\n",
    "\r\n",
    "while cap.isOpened() :\r\n",
    "    #Read new frame\r\n",
    "    ret, frame = cap.read()\r\n",
    "    if ret == True :\r\n",
    "        cv2.imshow('Frame', frame)\r\n",
    "        \r\n",
    "        if cv2.waitKey(33) & 0xFF == ord('q') : # Period control f - 1/T\r\n",
    "            break\r\n",
    "    else :\r\n",
    "        break\r\n",
    "    \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "vid = cv2.VideoCapture('./videos/Ant Tracking Hard.mp4')\r\n",
    "\r\n",
    "while vid.isOpened() :\r\n",
    "    ret, frame = vid.read()\r\n",
    "    \r\n",
    "    if ret :\r\n",
    "        cv2.imshow('Video frame', frame)\r\n",
    "\r\n",
    "        if cv2.waitKey(int(1000/24)) & 0xFF == ord('q') : # this line control the period between image frame\r\n",
    "            break\r\n",
    "    else :\r\n",
    "        break\r\n",
    "vid.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "    Lucus-Kanade Sparse Optical Flow \n",
    "</h1> <br>\n",
    "<h2 style=\"text-align: left\">\n",
    "    <a href=\"https://docs.opencv.org/4.5.3/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\"> calcOpticalFlowPyrLK()</a>\n",
    "    is a Lucas-Kanade Spares Optical Flow built-in OpenCV function inside \n",
    "    <a href=\"https://docs.opencv.org/4.5.3/dc/d6b/group__video__track.html\"> Object Tracking </a>\n",
    "    module.\n",
    "</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def lucas_kanade_optical_flow(video_device) :\r\n",
    "\r\n",
    "    cap = cv2.VideoCapture(video_device)\r\n",
    "    # params for ShiTomasi corner detection\r\n",
    "    feature_params = dict( maxCorners = 500,\r\n",
    "                        qualityLevel = 0.03,\r\n",
    "                        minDistance = 7,\r\n",
    "                        blockSize = 25 )\r\n",
    "\r\n",
    "    # Parameters for lucas kanade optical flow\r\n",
    "    lk_params = dict( winSize  = (21,21),\r\n",
    "                    maxLevel = 3,\r\n",
    "                    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\r\n",
    "\r\n",
    "    #Create some random colors\r\n",
    "    colors = np.random.randint(0, 255, (500, 3)) # 500 values 3 channel\r\n",
    "\r\n",
    "    #Take first frame and find corner\r\n",
    "    ret, old_frame = cap.read()\r\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\r\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params) # Feature detection, Harris corner with Shi-Tomasi response function\r\n",
    "\r\n",
    "    # Create a mask image for drawing overlay\r\n",
    "    mask = np.zeros_like(old_frame)\r\n",
    "\r\n",
    "    while cap.isOpened() :\r\n",
    "        \r\n",
    "        ret, frame = cap.read()\r\n",
    "\r\n",
    "        if ret :\r\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n",
    "\r\n",
    "            #calculate optical flow \r\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(\r\n",
    "                old_gray, frame_gray, p0, None, **lk_params\r\n",
    "            )\r\n",
    "\r\n",
    "            # Select good points\r\n",
    "            good_new = p1[st == 1]\r\n",
    "            good_old = p0[st == 1]\r\n",
    "\r\n",
    "            # Traceline drawing\r\n",
    "            for i, (new, old) in enumerate(zip(good_new, good_old)):\r\n",
    "                a, b = new.ravel().astype(int)\r\n",
    "                c, d = old.ravel().astype(int)\r\n",
    "                mask = cv2.line(mask, (a, b), (c, d), colors[i].tolist(), 2)\r\n",
    "                frame = cv2.circle(frame, (a,b), 5, colors[i].tolist(), -1)\r\n",
    "            \r\n",
    "            compare_img = cv2.hconcat([frame, mask])\r\n",
    "            disp_img = cv2.add(frame, mask)\r\n",
    "            cv2.imshow('compare', compare_img)\r\n",
    "            cv2.imshow('frame', disp_img)\r\n",
    "\r\n",
    "            key = cv2.waitKey(27) & 0xFF\r\n",
    "            if key == 27 or key == ord('q') :\r\n",
    "                break\r\n",
    "            elif key == ord('c') : # clear mask\r\n",
    "                mask = np.zeros_like(old_frame)\r\n",
    "                p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\r\n",
    "            else :\r\n",
    "                #Update the previous frame and previous points\r\n",
    "                old_gray = frame_gray.copy()\r\n",
    "                p0 = good_new.reshape(-1, 1, 2)\r\n",
    "        else :\r\n",
    "            break\r\n",
    "\r\n",
    "    cap.release()\r\n",
    "    cv2.destroyAllWindows()\r\n",
    "\r\n",
    "lucas_kanade_optical_flow(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "    Farnebäck Optical Flow\n",
    "</h1> <br>\n",
    "<h2 style=\"text-align: left\">\n",
    "    <a href=\"https://docs.opencv.org/4.5.3/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\"> calcOpticalFlowFarneback()</a>\n",
    "    is a Farnebäck Dense Optical Flow built-in OpenCV function inside \n",
    "    <a href=\"https://docs.opencv.org/4.5.3/dc/d6b/group__video__track.html\"> Object Tracking </a>\n",
    "    module. <br>\n",
    "    <a href=\"https://docs.opencv.org/4.5.3/d2/de8/group__core__array.html#gac5f92f48ec32cacf5275969c33ee837d\">cartToPolar() </a>\n",
    "    is a utility function for cartesian to polar conversion\n",
    "</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def farneback_dense_optical_flow(video_device) :\r\n",
    "    cap = cv2.VideoCapture(video_device)\r\n",
    "\r\n",
    "    ret, frame = cap.read()\r\n",
    "    last_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n",
    "    hsv = np.zeros_like(frame)\r\n",
    "    hsv[:, :, 1] = 255\r\n",
    "\r\n",
    "    while cap.isOpened() :\r\n",
    "        ret, frame = cap.read()\r\n",
    "\r\n",
    "        if ret :\r\n",
    "            \r\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n",
    "\r\n",
    "            flow = cv2.calcOpticalFlowFarneback(last_frame, frame_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0) # flow dx dy\r\n",
    "            \r\n",
    "            mag, ang = cv2.cartToPolar(flow[:, :, 0], flow[:, :, 1])\r\n",
    "            hsv[:, :, 0] = ang*(180/np.pi/2)\r\n",
    "            hsv[:, :, 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\r\n",
    "\r\n",
    "            flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\r\n",
    "\r\n",
    "            # thresh = cv2.inRange(hsv,(0, 0, 30), (20,255,255))\r\n",
    "            # motion_segment = cv2.bitwise_and(frame, frame, mask=thresh )\r\n",
    "            # cv2.imshow('thresh', motion_segment)\r\n",
    "           \r\n",
    "            last_frame = frame_gray.copy()\r\n",
    "\r\n",
    "            cv2.imshow('frame', frame)\r\n",
    "            cv2.imshow('flow', flow_rgb)\r\n",
    "            key = cv2.waitKey(27) & 0xFF\r\n",
    "            if key == 27 or key == ord('q') :\r\n",
    "                break\r\n",
    "\r\n",
    "        else :\r\n",
    "            break\r\n",
    "    \r\n",
    "    cap.release()\r\n",
    "    cv2.destroyAllWindows()\r\n",
    "            \r\n",
    "\r\n",
    "farneback_dense_optical_flow('./videos/Flow Visualization.mp4')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "    Optical Flow exercise\n",
    "</h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>แบบฝึกหัดที่ 10</h2>\n",
    "<h4>วัตถุประสงค์ </h1>\n",
    "\n",
    "- ทักษะการประยุกต์ใช้เทคนิค optical flow\n",
    "<h4>โจทย์</h4>\n",
    "\n",
    "- ให้นักศึกษาเขียน code ซอฟต์แวร์นำข้อมูลวิดีโอมาประมวลผลเพื่อติดตามการเคลื่อนไหวของคนหรือสิ่งของภายในภาพ (Crowd heatmapping)\n",
    "- ให้นักศึกษากำหนด ROI (พื้นที่ที่สนใจของภาพ, พื้นที่ในกรอบสี่เหลี่ยมของภาพ) เพื่อป้องกันการตรวจจับเสาและสภาพแวดล้อมที่ไม่เกี่ยวข้องภายนอก\n",
    "- ในการส่งงานให้นักศึกษาคอมเมนต์ code ที่ตนเองเขียนและอัพโหลดไปยัง github ของตนเองแล้วนำลิงก์ดังกล่าวไปโพสต์ส่งใน googleclassroom\n",
    "- video ต่าง ๆ ที่ถูกในในตัวอย่างด้านบนอยู่ภายใน directory <a href=\"https://github.com/jbinteam/010723305/tree/main/videos\">videos</a>\n",
    "- ชุดข้อมูลวิดีโอ <a href = \"https://github.com/jbinteam/010723305/blob/main/videos/grandcentral.mp4?raw=true\">grandcentral.mp4</a><br>\n",
    "- ผลลัพธ์ที่คาดหวัง <a href =\"https://youtu.be/UoXAaafHeQY\" >Youtube Video</a> \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "## coding here :D\r\n",
    "def lucas_kanade_optical_flow(video_device) :                                       #เรียกใช้งาน function ย่อย\r\n",
    "\r\n",
    "    cap = cv2.VideoCapture(video_device)\r\n",
    "    # params for ShiTomasi corner detection\r\n",
    "    feature_params = dict( maxCorners = 500,                                        #ตรวจจับวงกลมสีเขียวได้มากสุด 500                         \r\n",
    "                        qualityLevel = 0.02,                                        #ค่าคุณภาพของวิดีโออยู่ที่ 0.02\r\n",
    "                        minDistance = 7,                                            #ค่าระยะห่างน้อยที่สุดของแต่ละจุดอยู่ที่ 7 pixel\r\n",
    "                        blockSize = 25 )                                            #ขนาดบล็อกในการคำนวณอยูที่ 25 บล็อก\r\n",
    "\r\n",
    "    # Parameters for lucas kanade optical flow\r\n",
    "    lk_params = dict( winSize  = (21,21),                                           #เก็บค่าขนาดของวินโดร์ 21x21\r\n",
    "                    maxLevel = 3,                                                   #ค่าเลเวลอยู่ที่ 3\r\n",
    "                    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)) #ค่าที่ใช้ในการหยุดการทำงานอยู่ที่ 10 กับ 0.02\r\n",
    "\r\n",
    "    #Take first frame and find corner\r\n",
    "    ret, old_frame = cap.read()                                                     #อ่านค่าวิดีโอจาก cap ออกมาเป็น ret และ frame\r\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)                          #เปลี่ยนโมเดลสีจาก BRG เป็น Grayscale\r\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)             #Feature detection, Harris corner with Shi-Tomasi response function\r\n",
    "\r\n",
    "    # Create a mask image for drawing overlay\r\n",
    "    mask = np.zeros_like(old_frame)                                                 #สร้าง mask มีค่า 0 ที่มีขนาดเท่ากับ old_frame \r\n",
    "    mark = np.array([[170,30],[40,480],[720,480],[550,30]],np.int32)                #สร้างอาเรย์เก็บค่าตำแหน่ง 4 จุด เพื่อสร้างพื้นที่ที่สนใจ\r\n",
    "    roi = np.zeros(old_frame.shape[:2],np.uint8)                                    #สร้าง roi ที่มีค่า 0 มีขนาดเท่า old_frame ที่ตำแหน่ง 0-1\r\n",
    "    cv2.drawContours(roi,[mark],-1,255,-1,cv2.LINE_AA)                              #วาด contour ลงบน roi ตามตำแหน่งจุดในอาเรย์ mark                   \r\n",
    "\r\n",
    "    while cap.isOpened() :                                                          #กำหนดเงื่อนไขให้วิดีโอทำงานต่อไปเรื่อยๆ\r\n",
    "    \r\n",
    "        ret, frame = cap.read()                                                     #อ่านค่าวิดีโอจาก cap ออกมาเป็น ret และ frame\r\n",
    "\r\n",
    "        if ret :                                                                    #กำหนดเงื่อนไขในการตรวจสอบภาพ\r\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)                    #เปลี่ยนโมเดลสีของภาพจาก BRG เป็น Grayscale\r\n",
    "\r\n",
    "            #calculate optical flow \r\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(                                 #ทำการอ่านค่า optical flow โดยให้ค่าออกมาเป็นตำแหน่งปัจจุบัน สเตตัสและค่าผิดพลาด                             \r\n",
    "                old_gray, frame_gray, p0, None, **lk_params                         #ใส่่ค่าภาพก่อนหน้า ภาพปัจจุบัน ตำแหน่งก่อนหน้า และค่าพารามิเตอร์ใน lk_params  \r\n",
    "            )\r\n",
    "\r\n",
    "            # Select good points\r\n",
    "            good_new = p1[st == 1]                                                  #เลือกตำแหน่ง p1 ที่มีค่าเป็น 1 ของตำแหน่งปัจจุบันที่มีสถานะที่ดี\r\n",
    "            good_old = p0[st == 1]                                                  #เลือกตำแหน่ง p0 ที่มีค่าเป็น 1 ของตำแหน่งก่อนหน้าที่มีสถานะที่ดี\r\n",
    "\r\n",
    "            # Traceline drawing\r\n",
    "            for i, (new, old) in enumerate(zip(good_new, good_old)):                #วนลูปตามจำนวนของ good_new รวมกับ good_old\r\n",
    "                a, b = new.ravel().astype(int)                                      #เก็บค่าตำแหน่ง a,b ของตำแหน่งปัจจุบัน\r\n",
    "                c, d = old.ravel().astype(int)                                      #เก็บค่าตำแหน่ง c,d ของตำแหน่งก่อนหน้า\r\n",
    "                if a >= frame.shape[1]:                                             #ตรวจสอบค่า a ไม่ให้ค่าของ a มีค่ามากกว่า 720\r\n",
    "                    a = frame.shape[1]-1                                            \r\n",
    "                if b >= frame.shape[0]:                                             #ตรวจสอบค่า b ไม่ให้ค่าของ b มีค่ามากกว่า 480\r\n",
    "                    b = frame.shape[0]-1\r\n",
    "                if roi[b,a] == 255:                                                 #ตรวจสอบค่าในตำแหน่ง a,b ว่าอยู่ในพื้นที่ roi หรือไม่\r\n",
    "                    mask = cv2.line(mask, (a, b), (c, d), (0,0,255), 1)             #ถ้าอยู่ในพื้นที่ roi จะทำการวาดเส้นสีแดงจากตำแหน่งก่อนหน้าถึงตำแหน่งปัจจุบัน\r\n",
    "                    frame = cv2.circle(frame, (a,b), 5, (0,255,0), 1)               #วาดเส้นวงกลมสีเขียวบนตำแหน่งปัจจุบัน\r\n",
    "            \r\n",
    "            compare_img = cv2.hconcat([frame, mask])                                #เปรียบเทียบภาพ โดยนำภาพ frame กับ mask มารวมกัน                          \r\n",
    "            disp_img = cv2.add(frame, mask)                                         #นำภาพ frame กับ mask มารวมกันเป็น disp_img\r\n",
    "            cv2.drawContours(disp_img,[mark],-1,(255,0,0),1,cv2.LINE_AA)            #วาดเส้นสีน้ำเงินตามตำแหน่งจุดในอาร์เรย์ mask เพื่อสร้างเป็นพื้นที่ที่สนใจลงบน disp_img\r\n",
    "            # cv2.imshow('compare', compare_img)\r\n",
    "            cv2.imshow('frame', disp_img)                                           #แสดงภาพ disp_img\r\n",
    "\r\n",
    "            key = cv2.waitKey(33) & 0xFF                                            #อ่านค่า waitKey เท่ากับ 33 เพื่อที่จะเปิดภาพค้างไว้\r\n",
    "            if key == 27 or key == ord('q') :                                       #ตรวจสอบการกดปุ่ม esc หรือปุ่ม q\r\n",
    "                break\r\n",
    "            elif key == ord('c') or len(good_new) < 490 : # clear mask              #ตรวจสอบจำนวนของ good_new เมื่อมีค่าน้อยกว่า 480\r\n",
    "                p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params) #ตรวจจับฟีเจอร์ใหม่\r\n",
    "            else :                                                                  #ถ้าไม่มีการกดปุ่ม\r\n",
    "                #Update the previous frame and previous points\r\n",
    "                old_gray = frame_gray.copy()                                        #ทำการอัพเดทภาพปัจจุบันให้กลายเป็นภาพก่อนหน้า\r\n",
    "                p0 = good_new.reshape(-1, 1, 2)                                     #ทำการอัพเดทค่าตำแหน่ง good_new ให้กลายเป็นค่าตำแหน่งก่อนหน้า\r\n",
    "        else :\r\n",
    "            break\r\n",
    "\r\n",
    "    cap.release()                                                                   #คืนค่า\r\n",
    "    cv2.destroyAllWindows()                                                         #ปิดหน้าจอการทำงานทั้งหมด\r\n",
    "\r\n",
    "lucas_kanade_optical_flow('./videos/grandcentral.mp4')                              #เรียกใช้งานวิดีโอ grancentral.mp4              "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71d0282865cd4ecc03f1bce08c2529c4183d92e0dcfdfe966c5fb7b2a116731e"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}